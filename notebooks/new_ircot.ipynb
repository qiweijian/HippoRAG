{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qwj/code/HippoRAG\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ircot_hipporag_v3.py [-h] [--corpus_name {2wikihopqa,hotpotqa,musique}]\n",
      "                            [--extraction_model {openai,together}]\n",
      "                            [--extraction_model_name {meta-llama_Llama-3-8b-chat-hf,gpt-3.5-turbo-1106,meta-llama_Llama-3-70b-chat-hf}]\n",
      "                            [--graph_creating_retriever_name GRAPH_CREATING_RETRIEVER_NAME]\n",
      "                            [--extraction_type EXTRACTION_TYPE]\n",
      "                            [--graph_type GRAPH_TYPE]\n",
      "                            [--sim_threshold SIM_THRESHOLD]\n",
      "                            [--node_specificity [NODE_SPECIFICITY]]\n",
      "                            [--no_node_specificity]\n",
      "                            [--doc_ensemble [DOC_ENSEMBLE]]\n",
      "                            [--colbert_config COLBERT_CONFIG]\n",
      "                            [--dpr_only [DPR_ONLY]] [--graph_alg GRAPH_ALG]\n",
      "                            [--damping DAMPING]\n",
      "                            [--recognition_threshold RECOGNITION_THRESHOLD]\n",
      "                            [--corpus_path CORPUS_PATH]\n",
      "                            [--linking_retriever_name LINKING_RETRIEVER_NAME]\n",
      "                            [--prompt PROMPT] [--num_demo NUM_DEMO]\n",
      "                            [--max_steps MAX_STEPS] [--top_k TOP_K]\n",
      "                            [--force_retry [FORCE_RETRY]]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --corpus_name {2wikihopqa,hotpotqa,musique}\n",
      "                        Name of the dataset to use for retrieval (default:\n",
      "                        hotpotqa)\n",
      "  --extraction_model {openai,together}\n",
      "                        LLM provider for query NER, e.g., 'openai' or\n",
      "                        'together' (default: openai)\n",
      "  --extraction_model_name {meta-llama_Llama-3-8b-chat-hf,gpt-3.5-turbo-1106,meta-llama_Llama-3-70b-chat-hf}\n",
      "                        The extraction model to be used. (default:\n",
      "                        gpt-3.5-turbo-1106)\n",
      "  --graph_creating_retriever_name GRAPH_CREATING_RETRIEVER_NAME\n",
      "                        Retrieval encoder used to link query named entities\n",
      "                        with query nodes (default: facebook/contriever)\n",
      "  --extraction_type EXTRACTION_TYPE\n",
      "                        Type of NER extraction during indexing (default: ner)\n",
      "  --graph_type GRAPH_TYPE\n",
      "                        Type of graph used by HippoRAG (default:\n",
      "                        facts_and_sim)\n",
      "  --sim_threshold SIM_THRESHOLD\n",
      "                        Synonymy threshold which was used to create the graph\n",
      "                        that will be used by HippoRAG (default: 0.8)\n",
      "  --node_specificity [NODE_SPECIFICITY]\n",
      "                        Flag that determines whether node specificity will be\n",
      "                        used (default: True)\n",
      "  --no_node_specificity\n",
      "                        Flag that determines whether node specificity will be\n",
      "                        used (default: False)\n",
      "  --doc_ensemble [DOC_ENSEMBLE]\n",
      "                        Flag to determine whether to use uncertainty-based\n",
      "                        ensembling (default: False)\n",
      "  --colbert_config COLBERT_CONFIG\n",
      "                        ColBERTv2 configuration (default: None)\n",
      "  --dpr_only [DPR_ONLY]\n",
      "                        Flag to determine whether HippoRAG will be used at all\n",
      "                        (default: False)\n",
      "  --graph_alg GRAPH_ALG\n",
      "                        Type of graph algorithm to be used for retrieval,\n",
      "                        defaults to PPR (default: ppr)\n",
      "  --damping DAMPING     Damping factor for PPR (default: 0.1)\n",
      "  --recognition_threshold RECOGNITION_THRESHOLD\n",
      "                        Threshold used for uncertainty-based ensembling\n",
      "                        (default: 0.9)\n",
      "  --corpus_path CORPUS_PATH\n",
      "                        Path to the corpus file (see the format in README.md),\n",
      "                        not needed for now if extraction files are already\n",
      "                        present (default: None)\n",
      "  --linking_retriever_name LINKING_RETRIEVER_NAME\n",
      "                        Retriever name for linking, defaults to\n",
      "                        graph_creating_retriever_name if None (default: None)\n",
      "  --prompt PROMPT       The prompt to use (default: None)\n",
      "  --num_demo NUM_DEMO   The number of demo samples (default: 1)\n",
      "  --max_steps MAX_STEPS\n",
      "                        Maximum number of steps (default: None)\n",
      "  --top_k TOP_K         Retrieving k documents at each step (default: 8)\n",
      "  --force_retry [FORCE_RETRY]\n",
      "                        Force retry if necessary (default: False)\n"
     ]
    }
   ],
   "source": [
    "!python src/ircot_hipporag_v3.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ircotConfig(corpus_name='musique', extraction_model='openai', extraction_model_name='gpt-3.5-turbo-1106', graph_creating_retriever_name='colbertv2', extraction_type='ner', graph_type='facts_and_sim', sim_threshold=0.8, node_specificity=True, doc_ensemble=False, colbert_config={'root': 'data/lm_vectors/colbert/musique', 'doc_index_name': 'nbits_2', 'phrase_index_name': 'nbits_2'}, dpr_only=False, graph_alg='ppr', damping=0.5, recognition_threshold=0.9, corpus_path=None, linking_retriever_name='colbertv2', prompt=None, num_demo=1, max_steps=1, top_k=10, force_retry=True)\n",
      "Augmenting Graph from Similarity\n",
      "100%|██████████████████████████████████| 91729/91729 [00:01<00:00, 91019.54it/s]\n",
      "Building Graph: 100%|███████████████| 394346/394346 [00:00<00:00, 560961.39it/s]\n",
      "2024-07-26 08:13:15,806 - hipporag_v3 - INFO - Graph built: num vertices: 91729, num_edges: 394235\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/qwj/code/HippoRAG/src/ircot_hipporag_v3.py\", line 168, in <module>\n",
      "    rag = HippoRAGv3(ircot_config)\n",
      "  File \"/home/qwj/code/HippoRAG/src/hipporag_v3.py\", line 144, in __init__\n",
      "    self.load_embeddings()\n",
      "  File \"/home/qwj/code/HippoRAG/src/hipporag_v3.py\", line 171, in load_embeddings\n",
      "    colbertv2_index(self.phrases.tolist(), self.config.corpus_name, 'phrase', self.config.colbert_config['phrase_index_name'], overwrite='reuse')\n",
      "  File \"/home/qwj/code/HippoRAG/./src/colbertv2_indexing.py\", line 30, in colbertv2_index\n",
      "    indexer = Indexer(checkpoint=checkpoint_path, config=config)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/colbert/indexer.py\", line 24, in __init__\n",
      "    self.checkpoint_config = ColBERTConfig.load_from_checkpoint(checkpoint)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/colbert/infra/config/base_config.py\", line 66, in load_from_checkpoint\n",
      "    checkpoint_path = hf_hub_download(\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/huggingface_hub/file_download.py\", line 1282, in _hf_hub_download_to_cache_dir\n",
      "    (url_to_download, etag, commit_hash, expected_size, head_call_error) = _get_metadata_or_catch_error(\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/huggingface_hub/file_download.py\", line 1722, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/huggingface_hub/file_download.py\", line 1645, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/huggingface_hub/file_download.py\", line 372, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/huggingface_hub/file_download.py\", line 395, in _request_wrapper\n",
      "    response = get_session().request(method=method, url=url, **params)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/huggingface_hub/utils/_http.py\", line 66, in send\n",
      "    return super().send(request, *args, **kwargs)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 1099, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/urllib3/connection.py\", line 616, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/urllib3/connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "  File \"/home/qwj/miniconda3/envs/hipporag/lib/python3.9/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Export environment variables\n",
    "os.environ['OPENAI_API_KEY'] = 'aegsdvfhuijoak'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "!python3 src/ircot_hipporag_v3.py \\\n",
    "    --corpus_name musique \\\n",
    "    --extraction_model openai \\\n",
    "    --extraction_model_name gpt-3.5-turbo-1106 \\\n",
    "    --graph_creating_retriever_name colbertv2 \\\n",
    "    --max_steps 1 \\\n",
    "    --sim_threshold 0.8 \\\n",
    "    --damping 0.5 \\\n",
    "    --top_k 10 \\\n",
    "    --force_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def recall_dict_to_columns(row):\n",
    "    for k, v in row['recall'].items():\n",
    "        row[f'recall@{k}'] = v\n",
    "    return row\n",
    "\n",
    "def show_eval(file_path):\n",
    "    result = pd.read_json(file_path)\n",
    "    result = result.apply(recall_dict_to_columns, axis=1).drop('recall', axis=1)\n",
    "    print(result[[f'recall@{k}' for k in [2, 5, 10, 100]]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@2      0.405829\n",
      "recall@5      0.518498\n",
      "recall@10     0.592166\n",
      "recall@100    0.592166\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "show_eval(\"output/ircot_v3/ircot_results_musique_hipporag_colbertv2_demo_1_gpt-3.5-turbo-1106_no_ensemble_step_1_top_10_sim_thresh_0.8_damping_0.5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@2      0.406496\n",
      "recall@5      0.516414\n",
      "recall@10     0.589249\n",
      "recall@100    0.589249\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "show_eval(\"output/ircot_v3/ircot_results_musique_hipporag_colbertv2_demo_1_gpt-3.5-turbo-1106_no_ensemble_step_1_top_10_sim_thresh_0.8_damping_0.5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ircotConfig(corpus_name='musique', extraction_model='openai', extraction_model_name='gpt-3.5-turbo-1106', graph_creating_retriever_name='facebook/contriever', extraction_type='ner', graph_type='facts_and_sim', sim_threshold=0.8, node_specificity=True, doc_ensemble=False, colbert_config=None, dpr_only=False, graph_alg='ppr', damping=0.5, recognition_threshold=0.9, corpus_path=None, linking_retriever_name='facebook/contriever', prompt=None, num_demo=1, max_steps=1, top_k=10, force_retry=True)\n",
      "Building Graph: 100%|███████████████| 349755/349755 [00:00<00:00, 569188.79it/s]\n",
      "2024-07-19 15:14:26,907 - hipporag_v3 - INFO - Graph built: num vertices: 91729, num_edges: 349644\n",
      "2024-07-19 15:14:26,960 - hipporag_v3 - INFO - Loading node vectors from: data/lm_vectors/facebook_contriever_mean/encoded_strings.txt\n",
      "2024-07-19 15:14:27,557 - hipporag_v3 - INFO - 1 phrases did not have vectors.\n",
      "Loaded 0 results from output/ircot_v3/ircot_results_musique_hipporag_facebook_contriever_demo_1_gpt-3.5-turbo-1106_no_ensemble_step_1_top_10_sim_thresh_0.8_damping_0.5.json\n",
      "IRCoT retrieval: 100%|██████████████████████| 1000/1000 [12:54<00:00,  1.29it/s]\n",
      "Saved 1000 results to output/ircot_v3/ircot_results_musique_hipporag_facebook_contriever_demo_1_gpt-3.5-turbo-1106_no_ensemble_step_1_top_10_sim_thresh_0.8_damping_0.5.json\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Export environment variables\n",
    "os.environ['OPENAI_API_KEY'] = 'aegsdvfhuijoak'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "!python3 src/ircot_hipporag_v3.py \\\n",
    "    --corpus_name musique \\\n",
    "    --extraction_model openai \\\n",
    "    --extraction_model_name gpt-3.5-turbo-1106 \\\n",
    "    --graph_creating_retriever_name facebook/contriever \\\n",
    "    --max_steps 1 \\\n",
    "    --sim_threshold 0.8 \\\n",
    "    --damping 0.5 \\\n",
    "    --top_k 10 \\\n",
    "    --force_retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eval(\"output/ircot_v3/ircot_results_musique_hipporag_facebook_contriever_demo_1_gpt-3.5-turbo-1106_no_ensemble_step_1_top_10_sim_thresh_0.8_damping_0.5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@2      0.409579\n",
      "recall@5      0.520830\n",
      "recall@10     0.589332\n",
      "recall@100    0.589332\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "show_eval(\"output/ircot_v3/ircot_results_musique_hipporag_facebook_contriever_demo_1_gpt-3.5-turbo-1106_no_ensemble_step_1_top_10_sim_thresh_0.8_damping_0.5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@2      0.410912\n",
      "recall@5      0.521497\n",
      "recall@10     0.587832\n",
      "recall@100    0.587832\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "show_eval(\"output/ircot_v3/ircot_results_musique_hipporag_facebook_contriever_demo_1_gpt-3.5-turbo-1106_no_ensemble_step_1_top_10_sim_thresh_0.8_damping_0.5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipporag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
