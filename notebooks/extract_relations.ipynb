{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"4,5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qwj/code/HippoRAG\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "openie_post_ner_instruction = \"\"\"Your task is to extract the relations from the given query and named entity lists. \n",
    "Respond with a JSON list of relations, with each relation representing a relationship helpful to solve the query. \n",
    "\"\"\"\n",
    "\n",
    "openie_post_ner_frame = \"\"\"\n",
    "Query:\n",
    "```\n",
    "What language were books being translated into during the era of Haymo of Faversham?\n",
    "```\n",
    "{\"named_entities\":[\"books\", \"language\", \"Haymo of Faversham\"]}\n",
    "\"\"\"\n",
    "ai_output = \"\"\"\n",
    "{\"relations\": [\"being translated into\", \"during the era of\"]}\n",
    "\"\"\"\n",
    "\n",
    "real_input_template = \"\"\"\n",
    "Query:\n",
    "```\n",
    "{passage}\n",
    "```\n",
    "{named_entity_json}\n",
    "\"\"\"\n",
    "\n",
    "def llama3_template(passage, named_entity_json):\n",
    "    real_input = real_input_template.format(passage = passage, named_entity_json=named_entity_json)\n",
    "    return \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\" + openie_post_ner_instruction + \"<|eot_id|>\" + \\\n",
    "    \"<|start_header_id|>user<|end_header_id|>\" + openie_post_ner_frame + \"<|eot_id|>\" + \\\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\" + ai_output + \"<|eot_id|>\" + \\\n",
    "    \"<|start_header_id|>user<|end_header_id|>\" + real_input + \"<|eot_id|>\" + \\\n",
    "     \"<|start_header_id|>assistant<|end_header_id|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>question</th>\n",
       "      <th>question_decomposition</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_aliases</th>\n",
       "      <th>answerable</th>\n",
       "      <th>triples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2hop__13548_13529</td>\n",
       "      <td>[{'idx': 0, 'title': 'Lionel Messi', 'paragrap...</td>\n",
       "      <td>When was the person who Messi's goals in Copa ...</td>\n",
       "      <td>[{'id': 13548, 'question': \"To whom was Messi'...</td>\n",
       "      <td>June 1982</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>{\"named_entities\": [\"Messi\", \"Copa del Rey\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3hop1__9285_5188_23307</td>\n",
       "      <td>[{'idx': 0, 'title': 'Member states of NATO', ...</td>\n",
       "      <td>What month did the Tripartite discussions begi...</td>\n",
       "      <td>[{'id': 9285, 'question': 'What was the nobili...</td>\n",
       "      <td>mid-June</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>{\"named_entities\": [\"Britain\", \"France\", \"Wars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2hop__766973_770570</td>\n",
       "      <td>[{'idx': 0, 'title': 'Minsk Region', 'paragrap...</td>\n",
       "      <td>What county is Erik Hort's birthplace a part of?</td>\n",
       "      <td>[{'id': 766973, 'question': 'Erik Hort &gt;&gt; plac...</td>\n",
       "      <td>Rockland County</td>\n",
       "      <td>['Rockland County, New York']</td>\n",
       "      <td>True</td>\n",
       "      <td>{\"named_entities\": [\"Erik Hort\"]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2hop__170823_120171</td>\n",
       "      <td>[{'idx': 0, 'title': 'Blast Corps', 'paragraph...</td>\n",
       "      <td>What year did the publisher of Labyrinth end?</td>\n",
       "      <td>[{'id': 170823, 'question': 'Labyrinth &gt;&gt; publ...</td>\n",
       "      <td>1986</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>{\"named_entities\": [\"Labyrinth\"]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2hop__511454_120259</td>\n",
       "      <td>[{'idx': 0, 'title': 'Kavangoland', 'paragraph...</td>\n",
       "      <td>When was Lady Godiva's birthplace abolished?</td>\n",
       "      <td>[{'id': 511454, 'question': 'Lady Godiva &gt;&gt; pl...</td>\n",
       "      <td>918</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>{\"named_entities\": [\"Lady Godiva's birthplace\"]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      id  \\\n",
       "0           0       2hop__13548_13529   \n",
       "1           1  3hop1__9285_5188_23307   \n",
       "2           2     2hop__766973_770570   \n",
       "3           3     2hop__170823_120171   \n",
       "4           4     2hop__511454_120259   \n",
       "\n",
       "                                          paragraphs  \\\n",
       "0  [{'idx': 0, 'title': 'Lionel Messi', 'paragrap...   \n",
       "1  [{'idx': 0, 'title': 'Member states of NATO', ...   \n",
       "2  [{'idx': 0, 'title': 'Minsk Region', 'paragrap...   \n",
       "3  [{'idx': 0, 'title': 'Blast Corps', 'paragraph...   \n",
       "4  [{'idx': 0, 'title': 'Kavangoland', 'paragraph...   \n",
       "\n",
       "                                            question  \\\n",
       "0  When was the person who Messi's goals in Copa ...   \n",
       "1  What month did the Tripartite discussions begi...   \n",
       "2   What county is Erik Hort's birthplace a part of?   \n",
       "3      What year did the publisher of Labyrinth end?   \n",
       "4       When was Lady Godiva's birthplace abolished?   \n",
       "\n",
       "                              question_decomposition           answer  \\\n",
       "0  [{'id': 13548, 'question': \"To whom was Messi'...        June 1982   \n",
       "1  [{'id': 9285, 'question': 'What was the nobili...         mid-June   \n",
       "2  [{'id': 766973, 'question': 'Erik Hort >> plac...  Rockland County   \n",
       "3  [{'id': 170823, 'question': 'Labyrinth >> publ...             1986   \n",
       "4  [{'id': 511454, 'question': 'Lady Godiva >> pl...              918   \n",
       "\n",
       "                  answer_aliases  answerable  \\\n",
       "0                             []        True   \n",
       "1                             []        True   \n",
       "2  ['Rockland County, New York']        True   \n",
       "3                             []        True   \n",
       "4                             []        True   \n",
       "\n",
       "                                             triples  \n",
       "0  {\"named_entities\": [\"Messi\", \"Copa del Rey\", \"...  \n",
       "1  {\"named_entities\": [\"Britain\", \"France\", \"Wars...  \n",
       "2                  {\"named_entities\": [\"Erik Hort\"]}  \n",
       "3                  {\"named_entities\": [\"Labyrinth\"]}  \n",
       "4   {\"named_entities\": [\"Lady Godiva's birthplace\"]}  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'musique'\n",
    "queries = pd.read_csv(f\"output/{dataset}_queries.named_entity_output.tsv\", sep='\\t')\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = []\n",
    "for i, row in queries.iterrows():\n",
    "    passage = row.get('query', row.get('question'))\n",
    "    named_entity_json = row['triples']\n",
    "    prompts.append(llama3_template(passage, named_entity_json))\n",
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>Your task is to extract the relations from the given query and named entity lists. \n",
      "Respond with a JSON list of relations, with each relation representing a relationship helpful to solve the query. \n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Query:\n",
      "```\n",
      "What language were books being translated into during the era of Haymo of Faversham?\n",
      "```\n",
      "{\"named_entities\":[\"books\", \"language\", \"Haymo of Faversham\"]}\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "{\"relations\": [\"being translated into\", \"during the era of\"]}\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Query:\n",
      "```\n",
      "When was the person who Messi's goals in Copa del Rey compared to get signed by Barcelona?\n",
      "```\n",
      "{\"named_entities\": [\"Messi\", \"Copa del Rey\", \"Barcelona\"]}\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 12:24:40,700\tINFO worker.py:1749 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-04 12:24:41 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='/data/qwj/model/llama3_8b_instruct_hf', speculative_config=None, tokenizer='/data/qwj/model/llama3_8b_instruct_hf', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=/data/qwj/model/llama3_8b_instruct_hf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-04 12:24:45 utils.py:660] Found nccl from library /home/qwj/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m INFO 07-04 12:24:45 utils.py:660] Found nccl from library /home/qwj/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 07-04 12:24:47 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.\n",
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m INFO 07-04 12:24:46 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.\n",
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m INFO 07-04 12:24:46 selector.py:32] Using XFormers backend.\n",
      "INFO 07-04 12:24:47 selector.py:32] Using XFormers backend.\n",
      "INFO 07-04 12:25:03 pynccl_utils.py:43] vLLM is using nccl==2.18.1\n",
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m INFO 07-04 12:25:03 pynccl_utils.py:43] vLLM is using nccl==2.18.1\n",
      "INFO 07-04 12:25:04 utils.py:132] reading GPU P2P access cache from /home/qwj/.config/vllm/gpu_p2p_access_cache_for_4,5.json\n",
      "WARNING 07-04 12:25:04 custom_all_reduce.py:74] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m INFO 07-04 12:25:04 utils.py:132] reading GPU P2P access cache from /home/qwj/.config/vllm/gpu_p2p_access_cache_for_4,5.json\n",
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m WARNING 07-04 12:25:04 custom_all_reduce.py:74] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m INFO 07-04 12:25:07 model_runner.py:175] Loading model weights took 7.4829 GBINFO 07-04 12:25:07 model_runner.py:175] Loading model weights took 7.4829 GB\n",
      "\n",
      "INFO 07-04 12:25:10 distributed_gpu_executor.py:45] # GPU blocks: 12349, # CPU blocks: 4096\n",
      "INFO 07-04 12:25:11 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 07-04 12:25:11 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m INFO 07-04 12:25:11 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m INFO 07-04 12:25:11 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 07-04 12:25:17 model_runner.py:1017] Graph capturing finished in 6 secs.\n",
      "INFO 07-04 12:25:17 block_manager_v1.py:246] Automatic prefix caching is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayWorkerWrapper pid=444463)\u001b[0m INFO 07-04 12:25:17 model_runner.py:1017] Graph capturing finished in 6 secs.\n"
     ]
    }
   ],
   "source": [
    "model = LLM(model=\"/data/qwj/model/llama3_8b_instruct_hf\", tensor_parallel_size=2, enable_prefix_caching=True)\n",
    "sampling_params = SamplingParams(\n",
    "    n=1, stop=['<|eot_id|>'], max_tokens=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 10/10 [00:05<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(prompts[:10], sampling_params)\n",
    "output_text = [o.outputs[0].text for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n{\"relations\": [\"compared to\", \"signed by\", \"goals of\", \"person who\", \"when\"]}',\n",
       " '\\n\\n{\"relations\": [\"Tripartite discussions begin\", \"between\", \"the country where\", \"despite being headquartered in the nation called\", \"originated\"]}\\nNote: Some of these relations may not be directly relevant to the query, but they are all extracted from the text. To solve the query effectively, more context or specific information would be required.',\n",
       " '\\n\\n{\"relations\": [\"birthplace of\", \"part of a county\"]}',\n",
       " '\\n\\n{\"relations\": [\"publisher of\", \"end\"]}',\n",
       " '\\n\\n{\"relations\": [\"was abolished\"]}',\n",
       " '\\n\\n{\"relations\": [\"immediately north of\", \"region where\", \"location of the\", \"created\"]}',\n",
       " '\\n\\n{\"relations\": [\"is located next to the city where\", \"does the body of water break off into\", \"died in the city where\", \"is located by the city where\"]}',\n",
       " '\\n\\nNote: There is no information about the explorer, the city, or the record label\\'s headquarters in the named entities. We can\\'t extract any specific relations from the given information.\\n\\nHowever, we can still try to provide a general list of possible relations that could be relevant to the query:\\n\\n{\"relations\": [\"reach\", \"located\", \"larger than\"]}\\nPlease note that these relations are not specific to the query, but rather general possibilities that could be related to the query.',\n",
       " '\\n\\n{\"relations\": [\"the start of\", \"battle of the\", \"birthplace of\", \"performer of III\"]}',\n",
       " \"\\n\\nThere are no relations to extract from the query, as the query is about finding a single entity's birthdate and there are no other entities mentioned in the query.\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relations from results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json_dict(text):\n",
    "    pattern = r'\\{(?:[^{}]|(?:\\{(?:[^{}]|(?:\\{[^{}]*\\})*)*\\})*)*\\}'\n",
    "    match = re.search(pattern, text)\n",
    "\n",
    "    if match:\n",
    "        json_string = match.group()\n",
    "        try:\n",
    "            json_dict = json.loads(json_string)\n",
    "            return json_dict\n",
    "        except json.JSONDecodeError:\n",
    "            return ''\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'relations': ['compared to', 'signed by', 'goals of', 'person who', 'when']}\n",
      "1 {'relations': ['Tripartite discussions begin', 'between', 'the country where', 'despite being headquartered in the nation called', 'originated']}\n",
      "2 {'relations': ['birthplace of', 'part of a county']}\n",
      "3 {'relations': ['publisher of', 'end']}\n",
      "4 {'relations': ['was abolished']}\n",
      "5 {'relations': ['immediately north of', 'region where', 'location of the', 'created']}\n",
      "6 {'relations': ['is located next to the city where', 'does the body of water break off into', 'died in the city where', 'is located by the city where']}\n",
      "7 {'relations': ['reach', 'located', 'larger than']}\n",
      "8 {'relations': ['the start of', 'battle of the', 'birthplace of', 'performer of III']}\n",
      "9 \n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(output_text):\n",
    "    print(i, extract_json_dict(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1000/1000 [00:23<00:00, 42.82it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(prompts, sampling_params)\n",
    "extracted_relations = [extract_json_dict(o.outputs[0].text) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'paragraphs', 'question', 'question_decomposition',\n",
       "       'answer', 'answer_aliases', 'answerable', 'triples'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save = queries.copy()[['Unnamed: 0', 'id', 'question','triples']]\n",
    "data_to_save['relations'] = extracted_relations\n",
    "data_to_save.to_csv(f\"output/{dataset}_queries.entity_and_relations.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>triples</th>\n",
       "      <th>relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2hop__13548_13529</td>\n",
       "      <td>When was the person who Messi's goals in Copa ...</td>\n",
       "      <td>{\"named_entities\": [\"Messi\", \"Copa del Rey\", \"...</td>\n",
       "      <td>{'relations': ['was signed by', 'comprised of'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3hop1__9285_5188_23307</td>\n",
       "      <td>What month did the Tripartite discussions begi...</td>\n",
       "      <td>{\"named_entities\": [\"Britain\", \"France\", \"Wars...</td>\n",
       "      <td>{'relations': ['begin between', 'despite being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2hop__766973_770570</td>\n",
       "      <td>What county is Erik Hort's birthplace a part of?</td>\n",
       "      <td>{\"named_entities\": [\"Erik Hort\"]}</td>\n",
       "      <td>{'relations': ['birthplace of', 'part of a cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2hop__170823_120171</td>\n",
       "      <td>What year did the publisher of Labyrinth end?</td>\n",
       "      <td>{\"named_entities\": [\"Labyrinth\"]}</td>\n",
       "      <td>{'relations': ['publisher of', 'end']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2hop__511454_120259</td>\n",
       "      <td>When was Lady Godiva's birthplace abolished?</td>\n",
       "      <td>{\"named_entities\": [\"Lady Godiva's birthplace\"]}</td>\n",
       "      <td>{'relations': ['was abolished']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4hop2__71753_648517_70784_79935</td>\n",
       "      <td>When was the region immediately north of the r...</td>\n",
       "      <td>{\"named_entities\": [\"Israel\", \"Battle of Qurah...</td>\n",
       "      <td>{'relations': ['region immediately north of', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4hop1__94201_642284_131926_89261</td>\n",
       "      <td>Where does the body of water by the city where...</td>\n",
       "      <td>{\"named_entities\": [\"Southeast Library\", \"Gulf...</td>\n",
       "      <td>{'relations': ['by the city of', 'into', 'wher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4hop1__152562_5274_458768_33633</td>\n",
       "      <td>When did the explorer reach the city where the...</td>\n",
       "      <td>{\"named_entities\": [\"Vilaiyaadu Mankatha\"]}</td>\n",
       "      <td>{'relations': ['headquarters is located', 'lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3hop1__305282_282081_73772</td>\n",
       "      <td>When was the start of the battle of the birthp...</td>\n",
       "      <td>{\"named_entities\": [\"battle of the birthplace\"...</td>\n",
       "      <td>{'relations': ['start of the', 'of the birthpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2hop__655505_110949</td>\n",
       "      <td>What is the Till dom ensamma performer's birth...</td>\n",
       "      <td>{\"named_entities\": [\"Till dom ensamma\"]}</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                id  \\\n",
       "0           0                 2hop__13548_13529   \n",
       "1           1            3hop1__9285_5188_23307   \n",
       "2           2               2hop__766973_770570   \n",
       "3           3               2hop__170823_120171   \n",
       "4           4               2hop__511454_120259   \n",
       "5           5   4hop2__71753_648517_70784_79935   \n",
       "6           6  4hop1__94201_642284_131926_89261   \n",
       "7           7   4hop1__152562_5274_458768_33633   \n",
       "8           8        3hop1__305282_282081_73772   \n",
       "9           9               2hop__655505_110949   \n",
       "\n",
       "                                            question  \\\n",
       "0  When was the person who Messi's goals in Copa ...   \n",
       "1  What month did the Tripartite discussions begi...   \n",
       "2   What county is Erik Hort's birthplace a part of?   \n",
       "3      What year did the publisher of Labyrinth end?   \n",
       "4       When was Lady Godiva's birthplace abolished?   \n",
       "5  When was the region immediately north of the r...   \n",
       "6  Where does the body of water by the city where...   \n",
       "7  When did the explorer reach the city where the...   \n",
       "8  When was the start of the battle of the birthp...   \n",
       "9  What is the Till dom ensamma performer's birth...   \n",
       "\n",
       "                                             triples  \\\n",
       "0  {\"named_entities\": [\"Messi\", \"Copa del Rey\", \"...   \n",
       "1  {\"named_entities\": [\"Britain\", \"France\", \"Wars...   \n",
       "2                  {\"named_entities\": [\"Erik Hort\"]}   \n",
       "3                  {\"named_entities\": [\"Labyrinth\"]}   \n",
       "4   {\"named_entities\": [\"Lady Godiva's birthplace\"]}   \n",
       "5  {\"named_entities\": [\"Israel\", \"Battle of Qurah...   \n",
       "6  {\"named_entities\": [\"Southeast Library\", \"Gulf...   \n",
       "7        {\"named_entities\": [\"Vilaiyaadu Mankatha\"]}   \n",
       "8  {\"named_entities\": [\"battle of the birthplace\"...   \n",
       "9           {\"named_entities\": [\"Till dom ensamma\"]}   \n",
       "\n",
       "                                           relations  \n",
       "0  {'relations': ['was signed by', 'comprised of'...  \n",
       "1  {'relations': ['begin between', 'despite being...  \n",
       "2  {'relations': ['birthplace of', 'part of a cou...  \n",
       "3             {'relations': ['publisher of', 'end']}  \n",
       "4                   {'relations': ['was abolished']}  \n",
       "5  {'relations': ['region immediately north of', ...  \n",
       "6  {'relations': ['by the city of', 'into', 'wher...  \n",
       "7  {'relations': ['headquarters is located', 'lar...  \n",
       "8  {'relations': ['start of the', 'of the birthpl...  \n",
       "9                                                     "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_save.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipporag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
